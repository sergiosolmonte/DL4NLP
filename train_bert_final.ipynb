{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers"
      ],
      "metadata": {
        "id": "5dxmeAEV5Mqn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZJoOOpPL4xQp"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import torch\n",
        "import numpy as np\n",
        "from transformers import BertTokenizer, BertModel, AutoTokenizer, AutoModelForMaskedLM, AdamW\n",
        "#auto tokenizer and automodel are for bert-base-historical-german-cased from @redewiedergabe\n",
        "from torch import nn\n",
        "from torch.optim import Adam\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import f1_score, recall_score, confusion_matrix\n",
        "import seaborn as sn\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import pickle #to save the model into a file .pkl \n",
        "from google.colab import files\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def printProgressBar (iteration, total, prefix = '', suffix = '', decimals = 1, length = 100, fill = 'â–ˆ', printEnd = \"\\r\"):\n",
        "    \"\"\"\n",
        "    Call in a loop to create terminal progress bar\n",
        "    @params:\n",
        "        iteration   - Required  : current iteration (Int)\n",
        "        total       - Required  : total iterations (Int)\n",
        "        prefix      - Optional  : prefix string (Str)\n",
        "        suffix      - Optional  : suffix string (Str)\n",
        "        decimals    - Optional  : positive number of decimals in percent complete (Int)\n",
        "        length      - Optional  : character length of bar (Int)\n",
        "        fill        - Optional  : bar fill character (Str)\n",
        "        printEnd    - Optional  : end character (e.g. \"\\r\", \"\\r\\n\") (Str)\n",
        "    \"\"\"\n",
        "    percent = (\"{0:.\" + str(decimals) + \"f}\").format(100 * (iteration / float(total)))\n",
        "    filledLength = int(length * iteration // total)\n",
        "    bar = fill * filledLength + '-' * (length - filledLength)\n",
        "    print(f'\\r{prefix} |{bar}| {percent}% {suffix}', end = printEnd)\n",
        "    # Print New Line on Complete\n",
        "    if iteration == total: \n",
        "        print()"
      ],
      "metadata": {
        "id": "XkdO-NRZ5Xg_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-german-cased')\n",
        "#tokenizer = AutoTokenizer.from_pretrained(\"redewiedergabe/bert-base-historical-german-rw-cased\")\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = df['label'].values\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y\n",
        "\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-german-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear= nn.Linear(768,3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        relu_layer = self.relu(linear_output)\n",
        "        final_layer = relu_layer\n",
        "\n",
        "        return final_layer"
      ],
      "metadata": {
        "id": "nOBgSDjY5fLu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"original+back(train+val).csv\")\n",
        "#df=pd.read_csv(\"original(train+val).csv\")\n",
        "\n",
        "df=df[['text','label']]\n",
        "df.text.str.strip()\n",
        "\n",
        "df_train, df_val = np.split(df.sample(frac=1, random_state=42), \n",
        "                                     [int(.8*len(df))])\n",
        "\n"
      ],
      "metadata": {
        "id": "i46ewCBF6ZxU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = BertClassifier()\n",
        "\n",
        "label = 'GBert9.pkl'\n",
        "\n",
        "with open(label, 'wb') as fid:\n",
        "    pickle.dump(model,fid)  \n",
        "\n"
      ],
      "metadata": {
        "id": "WDl5Gy8l7CBP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.functional as F\n",
        "\n",
        "#PyTorch\n",
        "ALPHA = 0.8\n",
        "GAMMA = 2\n",
        "\n",
        "class FocalLoss(nn.Module):\n",
        "    def init(self, weight=None, size_average=True):\n",
        "        super(FocalLoss, self).init()\n",
        "\n",
        "    def forward(self, inputs, targets, alpha=ALPHA, gamma=GAMMA, smooth=1):\n",
        "        \n",
        "        #comment out if your model contains a sigmoid or equivalent activation layer\n",
        "        #inputs = F.sigmoid(inputs)       \n",
        "        \n",
        "        # turn target from indices to n x 3 dummy tensor\n",
        "        bs = len(targets)\n",
        "        y = torch.zeros(bs,3)\n",
        "        y[torch.arange(0, bs), targets.long()] = 1\n",
        "        targets = y\n",
        "        \n",
        "        #flatten label and prediction tensors\n",
        "        inputs = inputs.view(-1)\n",
        "        targets = targets.view(-1)\n",
        "        \n",
        "        #first compute binary cross-entropy \n",
        "        BCE = F.cross_entropy(inputs, targets, reduction='mean')\n",
        "        BCE_EXP = torch.exp(-BCE)\n",
        "        focal_loss = alpha * (1-BCE_EXP)**gamma * BCE\n",
        "                       \n",
        "        return focal_loss"
      ],
      "metadata": {
        "id": "f7jFyP_vrY6f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(model, train_data, val_data, learning_rate, epochs, label, hist):\n",
        "\n",
        "  # #To train only the classifier\n",
        "  #   for name, param in model.named_parameters():\n",
        "          \n",
        "\t#          if 'classifier' not in name: \n",
        "  #                 #print(name)\n",
        "  #                 param.no_grad=True\n",
        "\t# \t              #param.requires_grad = False\n",
        "                  \n",
        "    model.bert.requires_grad_(False)\n",
        "\n",
        "    train, val = Dataset(train_data), Dataset(val_data)\n",
        "\n",
        "    train_dataloader = torch.utils.data.DataLoader(train, batch_size=2, shuffle=True)\n",
        "    val_dataloader = torch.utils.data.DataLoader(val, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    #criterion = nn.CrossEntropyLoss()\n",
        "    criterion= FocalLoss()\n",
        "    optimizer = Adam(model.parameters(), lr= learning_rate)\n",
        "    #optimizer = AdamW(model.parameters(), lr = learning_rate, eps = 1e-8 )\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "            model = model.cuda()\n",
        "            criterion = criterion.cuda()\n",
        "\n",
        "    for epoch_num in range(epochs):\n",
        "\n",
        "            total_acc_train = 0\n",
        "            total_loss_train = 0\n",
        "\n",
        "            for train_input, train_label in tqdm(train_dataloader):\n",
        "\n",
        "                train_label = train_label.to(device)\n",
        "                mask = train_input['attention_mask'].to(device)\n",
        "                input_id = train_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                output = model(input_id, mask)\n",
        "\n",
        "                if hist==True:\n",
        "                    \"\"\" Only for bert-historical from pretrained\"\"\"\n",
        "                    output=output.logits\n",
        "\n",
        "                batch_loss = criterion(output, train_label.long())\n",
        "                total_loss_train += batch_loss.item()\n",
        "                \n",
        "                acc = (output.argmax(dim=1) == train_label).sum().item()\n",
        "                total_acc_train += acc\n",
        "\n",
        "                model.zero_grad()\n",
        "                batch_loss.backward()\n",
        "                optimizer.step()\n",
        "            \n",
        "            total_acc_val = 0\n",
        "            total_loss_val = 0\n",
        "\n",
        "            with torch.no_grad():\n",
        "\n",
        "                for val_input, val_label in val_dataloader:\n",
        "\n",
        "                    val_label = val_label.to(device)\n",
        "                    mask = val_input['attention_mask'].to(device)\n",
        "                    input_id = val_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "                    output = model(input_id, mask)\n",
        "\n",
        "                    if hist==True:\n",
        "                        \"\"\" Only for bert-historical from pretrained\"\"\"\n",
        "                        output=output.logits\n",
        "\n",
        "\n",
        "                    batch_loss = criterion(output, val_label.long())\n",
        "                    total_loss_val += batch_loss.item()\n",
        "                    \n",
        "                    acc = (output.argmax(dim=1) == val_label).sum().item()\n",
        "                    total_acc_val += acc\n",
        "                    \n",
        "            \n",
        "            with open(label, 'wb') as fid:\n",
        "                pickle.dump(model, fid)  \n",
        "\n",
        "            \n",
        "            print(\n",
        "                f'Epochs: {epoch_num + 1} | Train Loss: {total_loss_train / len(train_data): .3f} | Train Accuracy: {total_acc_train / len(train_data): .3f} | Val Loss: {total_loss_val / len(val_data): .3f} | Val Accuracy: {total_acc_val / len(val_data): .3f}')\n",
        "\n"
      ],
      "metadata": {
        "id": "3apr3iss5oR1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('GBert8.pkl', 'rb') as fid:\n",
        "     model=pickle.load(fid) \n",
        "\n",
        "#This command automatically update the model, I suggest you to use a different name and do not rewrite it.\n",
        "#train(model, df_train, df_val, 2e-5, 3, 'GBert7.pkl', hist=False)\n",
        "#train(model, df_train, df_val, 1e-5, 2, 'GBert8.pkl', hist=False)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8Kn5M7D3750A",
        "outputId": "664e89c3-0c03-454f-ddee-1f8a6c2b3053"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [48:00<00:00,  1.05s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 1 | Train Loss:  1.273 | Train Accuracy:  0.453 | Val Loss:  1.272 | Val Accuracy:  0.444\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [48:56<00:00,  1.07s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 2 | Train Loss:  1.272 | Train Accuracy:  0.456 | Val Loss:  1.270 | Val Accuracy:  0.463\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:32<00:00,  1.10s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 3 | Train Loss:  1.271 | Train Accuracy:  0.463 | Val Loss:  1.274 | Val Accuracy:  0.432\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:38<00:00,  1.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 4 | Train Loss:  1.271 | Train Accuracy:  0.467 | Val Loss:  1.270 | Val Accuracy:  0.461\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:47<00:00,  1.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 5 | Train Loss:  1.273 | Train Accuracy:  0.453 | Val Loss:  1.273 | Val Accuracy:  0.459\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:16<00:00,  1.10s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 6 | Train Loss:  1.270 | Train Accuracy:  0.468 | Val Loss:  1.269 | Val Accuracy:  0.464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:20<00:00,  1.10s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 7 | Train Loss:  1.272 | Train Accuracy:  0.458 | Val Loss:  1.270 | Val Accuracy:  0.472\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:52<00:00,  1.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 8 | Train Loss:  1.271 | Train Accuracy:  0.462 | Val Loss:  1.272 | Val Accuracy:  0.441\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:57<00:00,  1.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 9 | Train Loss:  1.272 | Train Accuracy:  0.461 | Val Loss:  1.270 | Val Accuracy:  0.464\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [49:41<00:00,  1.08s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 10 | Train Loss:  1.272 | Train Accuracy:  0.459 | Val Loss:  1.273 | Val Accuracy:  0.449\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [49:28<00:00,  1.08s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 11 | Train Loss:  1.273 | Train Accuracy:  0.453 | Val Loss:  1.271 | Val Accuracy:  0.452\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:54<00:00,  1.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 12 | Train Loss:  1.272 | Train Accuracy:  0.456 | Val Loss:  1.272 | Val Accuracy:  0.456\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:52<00:00,  1.11s/it]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epochs: 13 | Train Loss:  1.272 | Train Accuracy:  0.460 | Val Loss:  1.272 | Val Accuracy:  0.445\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:57<00:00,  1.11s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 14 | Train Loss:  1.271 | Train Accuracy:  0.462 | Val Loss:  1.271 | Val Accuracy:  0.453\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 2748/2748 [50:01<00:00,  1.09s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epochs: 15 | Train Loss:  1.270 | Train Accuracy:  0.467 | Val Loss:  1.271 | Val Accuracy:  0.457\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "files.download(label)"
      ],
      "metadata": {
        "id": "6vyk19Xh72cP",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f4b71b4d-98ba-4a59-f394-2e2d28763248"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_86d4eb2e-e8f4-45ca-8c18-a158cfd65125\", \"mybert_ft.pkl\", 436430837)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate(model, test_data, hist):\n",
        "\n",
        "    counts=test_data['label'].value_counts()\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    total_acc_class=[0,0,0]\n",
        "    y_true, y_pred= [],[]\n",
        "    \n",
        "    l = len(test_data)/2\n",
        "    i=0\n",
        "    printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "            \n",
        "              flag=0\n",
        "              \n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "              \n",
        "              y_true.append(test_label.data[0].item())\n",
        "\n",
        "              try:\n",
        "                y_true.append(test_label.data[1].item())\n",
        "              except:\n",
        "                    flag=1\n",
        "                    print(\"batch of size 1\")\n",
        "              #It is for bert-base-german-case (mybert)\n",
        "              if hist==False:\n",
        "                \n",
        "                y_pred.append(output.argmax(dim=1)[0].item())\n",
        "\n",
        "                if flag==0:\n",
        "                    y_pred.append(output.argmax(dim=1)[1].item()) \n",
        "\n",
        "                \n",
        "                \n",
        "                if(output.argmax(dim=1)[0] == test_label[0]):\n",
        "                    total_acc_class[int(test_label.data[0].item())]+=1\n",
        "                    \n",
        "                if flag ==0:    \n",
        "                    if(output.argmax(dim=1)[1] == test_label[1]):\n",
        "                        total_acc_class[int(test_label.data[1].item())]+=1\n",
        "                \n",
        "                \n",
        "                acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "                total_acc_test += acc\n",
        "             \n",
        "              \n",
        "              #For bert historical (historicalbert)\n",
        "              if hist == True:\n",
        "                y_pred.append( np.argmax(output.logits[0]))\n",
        "                y_pred.append(np.argmax(output.logits[1]))\n",
        "                if(np.argmax(output.logits[0]) == test_label[0]):\n",
        "                        \n",
        "                        total_acc_class[int(test_label.data[0].item())]+=1\n",
        "                        \n",
        "                if(np.argmax(output.logits[1]) == test_label[1]):\n",
        "\n",
        "                        total_acc_class[int(test_label.data[1].item())]+=1\n",
        "                \n",
        "                \n",
        "                acc = (np.argmax(output.logits) == test_label).sum().item()\n",
        "                total_acc_test += acc\n",
        "\n",
        "               #end bert historical\n",
        "              \n",
        "              # Update Progress Bar\n",
        "              printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "              i+=1\n",
        "    \n",
        "    print(\"all values: \", total_acc_class)\n",
        "    print(\"Accuracy per Class: \")\n",
        "    print(f\"Class 0 Nein -> { ( total_acc_class[0]/counts[0] if total_acc_class[0]>0 else 0  ): .3f} on {counts[0]} samples\")\n",
        "    print(f\"Class 1 Metapher ->  { total_acc_class[1]/counts[1]: .3f} on {counts[1]} samples\")\n",
        "    print(f\"Class 2 Kandidat ->  { total_acc_class[2]/counts[2]: .3f} on {counts[2]} samples\")\n",
        "    print(f'Test Accuracy: {total_acc_test / len(test_data): .3f} \\n\\n')\n",
        "    \n",
        "    print(\"F1-score: \")\n",
        "    score= f1_score(y_true, y_pred, average=None)\n",
        "    print(score)\n",
        "    print(\"Class 0 Nein score-> \", score[0])\n",
        "    print(\"Class 1 Metapher score -> \", score[1])\n",
        "    print(\"Class 2 Kandidat score -> \", score[2])\n",
        "    \n",
        "    print(\"F1 wih average Macro -> \",f1_score(y_true, y_pred, average='macro'),\"\\n\" )\n",
        "    \n",
        "    rec=recall_score(y_true, y_pred, average=None)\n",
        "    print(\"Class 0 Nein recall-> \", rec[0])\n",
        "    print(\"Class 1 Metapher recall -> \", rec[1])\n",
        "    print(\"Class 2 Kandidat recall -> \", rec[2])\n",
        "    print(\"Recall score macro -> \", recall_score(y_true, y_pred, average='macro'),\"\\n\")\n",
        "    \n",
        "    \n",
        "    print(\"Confusion Matrix: \\n\")\n",
        "    cfm= confusion_matrix(y_true, y_pred)\n",
        "    print(cfm)\n",
        "    df_cm = pd.DataFrame(cfm, range(3), range(3))\n",
        "    sn.set(font_scale=1.4) # for label size\n",
        "    sn.heatmap(df_cm, annot=True) # font size\n",
        "    plt.show()\n",
        "    "
      ],
      "metadata": {
        "id": "kLHAP2AojHXg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#load from pickle\n",
        "#label='mybert_ft_2.pkl'  #lr 2e-5 with adamW\n",
        "with open('mybert_ft_2linear.pkl', 'rb') as fid:\n",
        "     model=pickle.load(fid) \n",
        "df_test=pd.read_csv('original_test.csv')\n",
        "print(\"Evaluation: \")\n",
        "evaluate(model, df_test, hist=False)"
      ],
      "metadata": {
        "id": "o1AQ0qWTjShw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_cross(model, test_data, hist, class_score, macro_score, class_accuracy, class_recall, recall_macro, j):\n",
        "\n",
        "    counts=test_data['label'].value_counts()\n",
        "    test = Dataset(test_data)\n",
        "\n",
        "    test_dataloader = torch.utils.data.DataLoader(test, batch_size=2)\n",
        "\n",
        "    use_cuda = torch.cuda.is_available()\n",
        "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "    if use_cuda:\n",
        "\n",
        "        model = model.cuda()\n",
        "\n",
        "    total_acc_test = 0\n",
        "    total_acc_class=[0,0,0]\n",
        "    y_true, y_pred= [],[]\n",
        "    \n",
        "    l = len(test_data)/2\n",
        "    i=0\n",
        "    printProgressBar(0, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "\n",
        "    with torch.no_grad():\n",
        "\n",
        "        for test_input, test_label in test_dataloader:\n",
        "            \n",
        "              flag=0\n",
        "              \n",
        "              test_label = test_label.to(device)\n",
        "              mask = test_input['attention_mask'].to(device)\n",
        "              input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "\n",
        "              output = model(input_id, mask)\n",
        "              \n",
        "              y_true.append(test_label.data[0].item())\n",
        "\n",
        "              try:\n",
        "                y_true.append(test_label.data[1].item())\n",
        "              except:\n",
        "                    flag=1\n",
        "                    #print(\"batch of size 1\")\n",
        "              #It is for bert-base-german-case (mybert)\n",
        "              if hist==False:\n",
        "                \n",
        "                y_pred.append(output.argmax(dim=1)[0].item())\n",
        "\n",
        "                if flag==0:\n",
        "                    y_pred.append(output.argmax(dim=1)[1].item()) \n",
        "\n",
        "                \n",
        "                \n",
        "                if(output.argmax(dim=1)[0] == test_label[0]):\n",
        "                    total_acc_class[int(test_label.data[0].item())]+=1\n",
        "                    \n",
        "                if flag ==0:    \n",
        "                    if(output.argmax(dim=1)[1] == test_label[1]):\n",
        "                        total_acc_class[int(test_label.data[1].item())]+=1\n",
        "                \n",
        "                \n",
        "                acc = (output.argmax(dim=1) == test_label).sum().item()\n",
        "                total_acc_test += acc\n",
        "             \n",
        "              \n",
        "              #For bert historical (historicalbert)\n",
        "              if hist == True:\n",
        "                y_pred.append( np.argmax(output.logits[0]))\n",
        "                y_pred.append(np.argmax(output.logits[1]))\n",
        "                if(np.argmax(output.logits[0]) == test_label[0]):\n",
        "                        \n",
        "                        total_acc_class[int(test_label.data[0].item())]+=1\n",
        "                        \n",
        "                if(np.argmax(output.logits[1]) == test_label[1]):\n",
        "\n",
        "                        total_acc_class[int(test_label.data[1].item())]+=1\n",
        "                \n",
        "                \n",
        "                acc = (np.argmax(output.logits) == test_label).sum().item()\n",
        "                total_acc_test += acc\n",
        "\n",
        "               #end bert historical\n",
        "              \n",
        "              # Update Progress Bar\n",
        "              printProgressBar(i + 1, l, prefix = 'Progress:', suffix = 'Complete', length = 50)\n",
        "              i+=1\n",
        "    \n",
        "    class_accuracy[j][0]=total_acc_class[0]/counts[0]\n",
        "    class_accuracy[j][1]=total_acc_class[1]/counts[1]\n",
        "    class_accuracy[j][2]=total_acc_class[2]/counts[2]\n",
        "    \n",
        "    score= f1_score(y_true, y_pred, average=None)\n",
        "    class_score[j][0]=score[0]\n",
        "    class_score[j][1]=score[1]\n",
        "    class_score[j][2]=score[2]\n",
        "  \n",
        "    macro_score.append(f1_score(y_true, y_pred, average='macro'))\n",
        "    \n",
        "    rec= recall_score(y_true, y_pred, average=None)\n",
        "    class_recall[j][0]=rec[0]\n",
        "    class_recall[j][1]=rec[1]\n",
        "    class_recall[j][2]=rec[2]\n",
        "\n",
        "    recall_macro.append(recall_score(y_true, y_pred, average='macro'))\n",
        "    \n",
        "    "
      ],
      "metadata": {
        "id": "FKoUOuhADNDN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "models=[]\n",
        "\n",
        "for files in os.listdir(\"/content/\"):\n",
        "  if files.endswith(\"pkl\"): \n",
        "        # Your code comes here such as \n",
        "        models.append(files)\n"
      ],
      "metadata": {
        "id": "WJJuEWbqH4J1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_test=pd.read_csv('original_test.csv')\n",
        "\n",
        "one_split=df_test[df_test['label']==1].sample(frac=1,random_state=42)\n",
        "one_split=np.array_split(one_split,10)\n",
        "\n",
        "two_split=df_test[df_test['label']==2].sample(frac=1,random_state=42)\n",
        "two_split=np.array_split(two_split,10)\n",
        "\n",
        "zero_split=df_test[df_test['label']==0].sample(frac=1,random_state=42)\n",
        "zero_split=np.array_split(zero_split,10)\n",
        "\n",
        "\n",
        "shuffled = df_test.sample(frac=1, random_state=42)\n",
        "result = np.array_split(shuffled, 10)  \n",
        "\n",
        "results=pd.DataFrame( columns=['model', 'F1_score class 0','F1_score class 1','F1_score class 2', 'Macro F1', 'Accuracy class 0', 'Accuracy class 1', 'Accuracy class 2' ], index=range(len(models)))\n",
        "\n",
        "#loop over all the models in the current directory\n",
        "for k,mod in enumerate(sorted(models)):\n",
        "\n",
        "  print(k,mod)\n",
        "  class_score, macro_score, class_accuracy, class_recall, recall_macro = [3*[None]]*10,[],[3*[None]]*10,[3*[None]]*10,[]\n",
        "\n",
        "  with open(mod, 'rb') as fid:\n",
        "      model=pickle.load(fid) \n",
        "\n",
        "  eval_0=[]\n",
        "  eval_1=[]\n",
        "  eval_2=[]\n",
        "  eval_00=[]\n",
        "  eval_01=[]\n",
        "  eval_02=[]\n",
        "  j=0\n",
        "\n",
        "  for i in range(10):\n",
        "\n",
        "      \n",
        "      fold=pd.concat([zero_split[i], two_split[i], one_split[i]])\n",
        "      fold=fold.sample(frac=1, random_state=42)\n",
        "      fold.reset_index(drop=True, inplace=True)\n",
        "      evaluate_cross(model, fold, False, class_score, macro_score, class_accuracy, class_recall, recall_macro, j)\n",
        "      j+=1\n",
        "      for cs in class_score:\n",
        "          eval_0.append(cs[0])\n",
        "          eval_1.append(cs[1])\n",
        "          eval_2.append(cs[2])\n",
        "\n",
        "      for cs in class_accuracy:\n",
        "          eval_00.append(cs[0])\n",
        "          eval_01.append(cs[1])\n",
        "          eval_02.append(cs[2])\n",
        "\n",
        "     \n",
        "  results.loc[k,'model']=mod\n",
        "\n",
        "  \n",
        "  print(\"score: \", class_score)\n",
        "  \n",
        "  results.loc[k,'F1_score class 0']=np.mean(eval_0)\n",
        "  results.loc[k,'F1_score class 1']=np.mean(eval_1)\n",
        "  results.loc[k,'F1_score class 2']=np.mean(eval_2)\n",
        "  results.loc[k,'Macro F1']=np.mean(macro_score)\n",
        "\n",
        "  print(\"\\n\", class_accuracy)\n",
        "  \n",
        "  results.loc[k,'Accuracy class 0']=np.mean(eval_00)\n",
        "  results.loc[k,'Accuracy class 1']=np.mean(eval_01)\n",
        "  results.loc[k,'Accuracy class 2']=np.mean(eval_02)\n"
      ],
      "metadata": {
        "id": "citEhn9tH8AR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(results)\n",
        "results.to_csv(\"results1.csv\")"
      ],
      "metadata": {
        "id": "tFXFrcMOjP1L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files as gf\n",
        "gf.download('results.csv')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "AuoFx1ETtmJW",
        "outputId": "45dad768-36e2-4029-99d4-1dd09af3be42"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_9a5d59e9-382c-4819-8817-02b622c9b164\", \"results.csv\", 1983)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gf.download('GBert8.pkl')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "YqvwOKbyuRsb",
        "outputId": "47a832c6-19e5-446d-8e44-0acd14366e4c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_ee510938-2034-4510-a531-bfc659821d30\", \"mybert_ft_1.pkl\", 436430837)"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}